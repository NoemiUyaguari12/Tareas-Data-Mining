{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de este ejercicio es implementar un modelo de regresión lineal utilizando TensorFlow para predecir los precios de la vivienda según el conjunto de datos de vivienda de California. El conjunto de datos contiene varias características, como el ingreso promedio, la edad promedio de la vivienda y más. Su tarea es construir un modelo de regresión lineal y evaluar su desempeño."
      ],
      "metadata": {
        "id": "krWtDNhUcFha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IHIkCMKwcG5z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el Data Set California Housing, y dividirlo en caracteristicas y variable objetivo."
      ],
      "metadata": {
        "id": "DC4dba-sd6vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = fetch_california_housing()\n",
        "X = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\n",
        "y = pd.Series(raw['target'])\n",
        "print (X)\n",
        "#print (y)\n"
      ],
      "metadata": {
        "id": "koz1sd3JcTB9",
        "outputId": "853e2595-f224-43c0-e7b7-4e005e14b630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "...       ...       ...       ...        ...         ...       ...       ...   \n",
            "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
            "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
            "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
            "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
            "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
            "\n",
            "       Longitude  \n",
            "0        -122.23  \n",
            "1        -122.22  \n",
            "2        -122.24  \n",
            "3        -122.25  \n",
            "4        -122.25  \n",
            "...          ...  \n",
            "20635    -121.09  \n",
            "20636    -121.21  \n",
            "20637    -121.22  \n",
            "20638    -121.32  \n",
            "20639    -121.24  \n",
            "\n",
            "[20640 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividir el conjunto"
      ],
      "metadata": {
        "id": "6I8Mh5V4f16D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "SmGnMtB7f3OC",
        "outputId": "d27343a8-178f-4c1a-ea33-143b3903314f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 8)\n",
            "(4128, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizar"
      ],
      "metadata": {
        "id": "UTi3hyoBdGmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "FamejA_6dJOc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escalar los datos de entrada"
      ],
      "metadata": {
        "id": "0c2NNi1x3kuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xicadb4r8qzh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertir los datos de entrenamiento y prueba a tensores de TensorFlow"
      ],
      "metadata": {
        "id": "7F8WYgoS8xs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = tf.constant(X_train_scaled, dtype=tf.float32)\n",
        "y_train_tensor = tf.constant(y_train.to_numpy().reshape(-1, 1), dtype=tf.float32)\n",
        "X_test_tensor = tf.constant(X_test_scaled, dtype=tf.float32)\n",
        "y_test_tensor = tf.constant(y_test.to_numpy().reshape(-1, 1), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "-ebhT1w180fD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir las variables para los pesos (W) y el sesgo (b) del modelo"
      ],
      "metadata": {
        "id": "-tz3mGqf83jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.random.normal(shape=(X_train.shape[1], 1)), dtype=tf.float32)\n",
        "b = tf.Variable(0.0, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "dKotUfcT88pm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir el modelo de regresión lineal"
      ],
      "metadata": {
        "id": "bJrJR88j89pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(X):\n",
        "    return tf.matmul(X, W) + b"
      ],
      "metadata": {
        "id": "9GvNH6Bv9ELg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir la función de pérdida como el error cuadrático medio entre los valores predichos y los valores verdaderos"
      ],
      "metadata": {
        "id": "os6V-mrI9Ly3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true))"
      ],
      "metadata": {
        "id": "TZtMr-X49PHd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegir un optimizador Gradient Descent para minimizar la función de pérdida"
      ],
      "metadata": {
        "id": "OPm8hj4P9RaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "lVjTj5D29WMw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Calcular las predicciones y la pérdida en el conjunto de entrenamiento\n",
        "        y_pred_train = linear_regression(X_train_tensor)\n",
        "        current_loss = loss(y_train_tensor, y_pred_train)\n",
        "\n",
        "    # Calcular los gradientes\n",
        "    gradients = tape.gradient(current_loss, [W, b])\n",
        "\n",
        "    # Actualizar los pesos y el sesgo utilizando el optimizador\n",
        "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        # Calcular la pérdida en el conjunto de prueba\n",
        "        y_pred_test = linear_regression(X_test_tensor)\n",
        "        test_loss = loss(y_test_tensor, y_pred_test)\n",
        "\n",
        "        # Imprimir la pérdida de entrenamiento y prueba a intervalos regulares\n",
        "        print(f\"Epoch {epoch}: Train Loss = {current_loss.numpy()}, Test Loss = {test_loss.numpy()}\")\n",
        "\n",
        "# Evaluar el modelo\n",
        "y_pred_test = linear_regression(X_test_tensor)\n",
        "mse = np.mean(np.square(y_pred_test - y_test.to_numpy().reshape(-1, 1)))\n",
        "\n",
        "\n",
        "print(\"MSE:\", mse)"
      ],
      "metadata": {
        "id": "N2WX8Gox3maH",
        "outputId": "96e8f0cb-d169-419c-8d3a-1f075d0702c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss = 11.275544166564941, Test Loss = 12.050978660583496\n",
            "Epoch 100: Train Loss = 0.7706097364425659, Test Loss = 0.7603852152824402\n",
            "Epoch 200: Train Loss = 0.6075896620750427, Test Loss = 0.6141864657402039\n",
            "Epoch 300: Train Loss = 0.5803281664848328, Test Loss = 0.5882248282432556\n",
            "Epoch 400: Train Loss = 0.5630595088005066, Test Loss = 0.5720024108886719\n",
            "Epoch 500: Train Loss = 0.5506919622421265, Test Loss = 0.5612785816192627\n",
            "Epoch 600: Train Loss = 0.5417554378509521, Test Loss = 0.5544008612632751\n",
            "Epoch 700: Train Loss = 0.5352873206138611, Test Loss = 0.5501816868782043\n",
            "Epoch 800: Train Loss = 0.5305999517440796, Test Loss = 0.5477737188339233\n",
            "Epoch 900: Train Loss = 0.5271987318992615, Test Loss = 0.5465810298919678\n",
            "MSE: 0.54618824\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Markdown Guide",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}